{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7d05b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "print('✓ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6511f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "data = pd.read_csv(\"/Users/Eswara Chaitanya/OneDrive/Documents/DNN_assignment/oral_cancer_balanced_900.csv\")\n",
    "primary_metric = ['Accuracy', 'AU Score','Precision', 'Recall', 'F1-Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef1353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Encode categorical variables completed. New shape of X: (900, 43)\n",
      "Train samples: 720\n",
      "Test samples: 180\n",
      "Split ratio: 80.0%\n",
      "Y values after encoding and scaling: (720,)\n"
     ]
    }
   ],
   "source": [
    "# 1. Separate features (X) and target (y)\n",
    "X = data.drop(['Oral Cancer (Diagnosis)'], axis=1)\n",
    "y = data['Oral Cancer (Diagnosis)'].map({'Yes': 1, 'No': 0})  # Convert target to binary\n",
    "#print(X.head)\n",
    "print(type(y))\n",
    "\n",
    "# 2. Handle missing values if any\n",
    "X.isnull().sum()\n",
    "X = X.fillna(X.select_dtypes(include=[np.number]).mean())\n",
    "\n",
    "# 3. Encode categorical variables\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "X=X_encoded.astype(float)\n",
    "print(f\"Encode categorical variables completed. New shape of X: {X.shape}\")\n",
    "\n",
    "# Train-test split (stratify when possible)\n",
    "stratify_arg = y if y.nunique() > 1 else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=stratify_arg)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Fill these after preprocessing\n",
    "train_samples = X_train_scaled.shape[0]      # Number of training samples\n",
    "test_samples = X_test_scaled.shape[0]        # Number of test samples\n",
    "train_test_ratio = train_samples/(train_samples+test_samples)  # e.g., 0.8 for 80-20 split\n",
    "\n",
    "print(f\"Train samples: {train_samples}\")\n",
    "print(f\"Test samples: {test_samples}\")\n",
    "print(f\"Split ratio: {train_test_ratio:.1%}\")\n",
    "print(f\"Y values after encoding and scaling: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2c28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel:\n",
    "    def __init__(self, lr=0.01, n_iters=1000): \n",
    "        self.lr = lr \n",
    "        self.n_iters = n_iters \n",
    "        self.weights = None \n",
    "        self.bias = None \n",
    "    def _sigmoid(self, z): \n",
    "        return 1 / (1 + np.exp(-z)) \n",
    "    def fit(self, X, y): \n",
    "        n_samples, n_features = X.shape \n",
    "        self.weights = np.zeros(n_features) \n",
    "        self.bias = 0 \n",
    "        for _ in range(self.n_iters):\n",
    "         linear_model = np.dot(X, self.weights) + self.bias \n",
    "         y_predicted = self._sigmoid(linear_model) \n",
    "         # gradients \n",
    "         dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y)) \n",
    "         db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "         # update \n",
    "         self.weights -= self.lr * dw \n",
    "         self.bias -= self.lr * db\n",
    "    def predict(self, X): \n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._sigmoid(linear_model) \n",
    "        return [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d000b8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
      "Accuracy: 1.0\n",
      "AUC Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "model = LogisticRegressionModel(lr=0.1, n_iters=1000) \n",
    "model.fit(X_train_scaled, y_train) \n",
    "preds = model.predict(X_test_scaled) \n",
    "print(\"Predictions:\", preds)\n",
    "# Accuracy \n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "# AUC Score (needs probabilities, not just class labels) \n",
    "y_probs = model._sigmoid(np.dot(X_test_scaled, model.weights) + model.bias) \n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "# Precision \n",
    "precision = precision_score(y_test, preds)\n",
    "# Recall\n",
    "recall = recall_score(y_test, preds)\n",
    "# F1 Score \n",
    "f1 = f1_score(y_test, preds)\n",
    "print(\"Accuracy:\", accuracy) \n",
    "print(\"AUC Score:\", auc) \n",
    "print(\"Precision:\", precision) \n",
    "print(\"Recall:\", recall) \n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34325eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n",
      "AUC Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# Initialize Decision Tree\n",
    "dt_clf = DecisionTreeClassifier( criterion=\"gini\", # or \"entropy\" \n",
    "max_depth=5, # limit depth to avoid overfitting\n",
    "random_state=42 \n",
    ")\n",
    "# Train \n",
    "dt_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions \n",
    "y_pred = dt_clf.predict(X_test) \n",
    "y_probs = dt_clf.predict_proba(X_test)[:, 1] # for AUC \n",
    "# Evaluation Metrics \n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "precision = precision_score(y_test, y_pred) \n",
    "recall = recall_score(y_test, y_pred) \n",
    "f1 = f1_score(y_test, y_pred) \n",
    "auc = roc_auc_score(y_test, y_probs) \n",
    "print(\"Accuracy:\", accuracy) \n",
    "print(\"Precision:\", precision) \n",
    "print(\"Recall:\", recall) \n",
    "print(\"F1 Score:\", f1) \n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc857e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Results:\n",
      "Accuracy: 0.9444444444444444\n",
      "Precision: 1.0\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.9411764705882353\n",
      "AUC Score: 0.9979012345679013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize K-Nearest Neighbors Classifier\n",
    "knn_clf = KNeighborsClassifier(\n",
    "    n_neighbors=5,      # Number of neighbors to consider\n",
    "    metric='euclidean'  # Distance metric\n",
    ")\n",
    "\n",
    "# Train\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn_clf.predict(X_test_scaled)\n",
    "y_probs = knn_clf.predict_proba(X_test_scaled)[:, 1]  # for AUC\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"KNN Classifier Results:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc96fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Results:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize Gaussian Naive Bayes Classifier\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Train\n",
    "nb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = nb_clf.predict(X_test_scaled)\n",
    "y_probs = nb_clf.predict_proba(X_test_scaled)[:, 1]  # for AUC\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Naive Bayes Classifier Results:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2293b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Results:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "AUC Score: 1.0\n",
      "\n",
      "Top 10 Important Features:\n",
      "Feature 6: 0.3047\n",
      "Feature 3: 0.1835\n",
      "Feature 4: 0.1670\n",
      "Feature 5: 0.1551\n",
      "Feature 2: 0.0909\n",
      "Feature 38: 0.0685\n",
      "Feature 41: 0.0098\n",
      "Feature 40: 0.0096\n",
      "Feature 39: 0.0073\n",
      "Feature 0: 0.0008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,      # Number of trees in the forest\n",
    "    max_depth=15,          # Maximum depth of trees\n",
    "    min_samples_split=5,   # Minimum samples required to split\n",
    "    min_samples_leaf=2,    # Minimum samples required at leaf node\n",
    "    random_state=42,\n",
    "    n_jobs=-1              # Use all processors\n",
    ")\n",
    "\n",
    "# Train\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_clf.predict(X_test_scaled)\n",
    "y_probs = rf_clf.predict_proba(X_test_scaled)[:, 1]  # for AUC\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Random Forest Classifier Results:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"AUC Score:\", auc)\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = rf_clf.feature_importances_\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "top_indices = np.argsort(feature_importance)[-10:][::-1]\n",
    "for idx in top_indices:\n",
    "    print(f\"Feature {idx}: {feature_importance[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b2ae759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Results:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "AUC Score: 1.0\n",
      "\n",
      "Top 10 Important Features:\n",
      "Feature 3: 0.3930\n",
      "Feature 2: 0.3025\n",
      "Feature 6: 0.2063\n",
      "Feature 4: 0.0656\n",
      "Feature 5: 0.0325\n",
      "Feature 37: 0.0000\n",
      "Feature 38: 0.0000\n",
      "Feature 39: 0.0000\n",
      "Feature 42: 0.0000\n",
      "Feature 41: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=100,           # Number of boosting rounds\n",
    "    max_depth=6,                # Maximum tree depth\n",
    "    learning_rate=0.1,          # Shrinkage (eta)\n",
    "    subsample=0.8,              # Fraction of samples for fitting trees\n",
    "    colsample_bytree=0.8,       # Fraction of features for fitting trees\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0                 # Silent mode\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_clf.predict(X_test_scaled)\n",
    "y_probs = xgb_clf.predict_proba(X_test_scaled)[:, 1]  # for AUC\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"XGBoost Classifier Results:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"AUC Score:\", auc)\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance_xgb = xgb_clf.feature_importances_\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "top_indices_xgb = np.argsort(feature_importance_xgb)[-10:][::-1]\n",
    "for idx in top_indices_xgb:\n",
    "    print(f\"Feature {idx}: {feature_importance_xgb[idx]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
